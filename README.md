# Youtube-Video-Data-Analysis

## Introduction

A huge repository of terabytes of data is generated each day from modern information systems and digital technologies such as the Internet of Things and cloud computing. This project focuses on analyzing the massive data generated by YouTube to extract valuable insights and improve the performance of channels. By incorporating video titles, categories, channel data, and time series information such as likes, dislikes, comment counts, video tags, and descriptions from 10 countries, we aim to understand trends at a granular level.

## Project Scope

The project involves building a scalable infrastructure for YouTube's video data analysis. The following analysis tasks will be performed:

1. Determining the year's top-trending videos based on user interactions.
2. Categorizing YouTube videos based on comments and statistics.
3. Analyzing the factors that affect a video's popularity.
4. Visualizing interesting factors discovered during the analysis.

To achieve this, we will utilize Talend as the data pipeline, Azure Cosmos DB as the target data store, and Tableau as the visualization tool.

## Architecture Diagram

![Architecture Diagram](architecture_diagram.png)

The architecture diagram illustrates the proposed implementation for YouTube data analysis. The project focuses on 10 countries, and the data is obtained in both CSV and JSON formats. The key steps involved are as follows:

1. Data Extraction: Raw data is fetched using a Python script and consolidated into a JSON file.
2. Data Movement: Talend is used to load the data into Azure Data Factory, with the merged JSON file as the source.
3. Azure to Cosmos DB: A trigger on Azure Data Factory is created to load the JSON file into Cosmos DB.
4. Data Visualization: Tableau is employed for data analysis and visualization of the given dataset.

## ER Diagram

![ER Diagram](er_diagram.png)

The project consists of 20 files in CSV and JSON formats for the selected countries. A Python script is used to merge these files and generate the FinalDataset.json. Additionally, a Region column is added to the final dataset.

## Project Implementation

### Consolidating Data

A Python script is utilized to consolidate the data into a single document. The script combines the data based on Region and Category_id, adding a region column to the CSV file and extracting relevant columns from the JSON file. The script merges the data and creates the FinalDataset.json file.

### Data Transfer from JSON to Cosmos DB

Azure Data Factory is used for transferring data from JSON to Azure Blob storage container. The process involves creating a container, setting up a Talend job to export the JSON file to the Azure Blob storage container, and creating a pipeline in Azure Data Factory for copying the data. The data is then validated, and the pipeline is executed to transport the data to Cosmos DB.

### Task Scheduler for Data Refresh

To ensure data is up-to-date, a Python script is created to download the data directly from the internet. A batch file and Windows Task Scheduler are used to automate the data refresh process on a daily basis.

### JSON File to Azure Blob Storage

A Talend job is built to load the JSON file into Azure Blob storage. This involves creating a shell script and a bash file of the ETL package. Windows Task Scheduler is used to run the generated bash file at specific intervals.

### Azure Blob Storage to Cosmos DB

A trigger is created on Azure Data Factory to load the JSON file from Azure Blob storage into Cosmos DB. The write behavior of the Azure Data Factory pipeline is set to Upsert for handling incremental data. The pipeline is triggered successfully, and the data is loaded into Cosmos DB.

## Data Visualization

Tableau is used for data analysis and visualization. The dashboards include:

- Visualization of countries with total numbers of videos.
- Video type analysis with likes, dislikes, and views.
- Analysis of comment counts and top 10 comment counts per video type.
- Category-wise distribution of the number of views.
- Top 10 channels and their number of views for each category.
- Top 10 video titles based on the number of views.

## Future Aspects

Future improvements and possibilities for the project include:

- Building scalable and adaptable code and tools.
- Exploring the use of Graph databases, such as Azure Gremlin, for analyzing relationships between entities.
- Incorporating data from multiple sources.
- Streamlining the integration process into a single pipeline.

